{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Will Bank's Clients subscribe to term deposit?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data set comes from https://www.kaggle.com/ishandutta/bank-marketing-data-set.\n",
    "This report is an extension of previous one called 'Classification Project- Comparing Different Methods', which can be found here: https://github.com/hannia941/Classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part is the same as in the last project (mentioned at the top). For more details please go to https://github.com/hannia941/Classification\n",
    "1. Loading the dataset\n",
    "2. Encoding categorical data\n",
    "3. Spliting data into training and testing set\n",
    "4. Feature Scaling\n",
    "No missing data was found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Loading the dataset\n",
    "bank_data = pd.read_csv('/Users/user/Desktop/Python/Classification Project/bank-additional-full.csv',sep = ';')\n",
    "bank_data.columns = ['age', 'job_type', 'marital', 'education', 'has_credit', 'has_house_loan', 'has_person_loan',\n",
    "       'contact', 'month', 'day_of_week', 'duration', 'campaign', 'pass_days',\n",
    "       'previous', 'prev_outcome', 'emp_var_rate', 'cpi',\n",
    "       'cci', 'euribor3m', 'nr_employed', 'class']\n",
    "bank_data_min = bank_data[['job_type', 'marital', 'education', 'has_credit', 'has_house_loan',\n",
    "                          'has_person_loan','contact', 'prev_outcome', 'age', 'campaign', 'previous',\n",
    "                          'emp_var_rate', 'cpi','cci', 'euribor3m', 'class']]\n",
    "\n",
    "y = bank_data_min.iloc[:,-1].values\n",
    "X = bank_data_min.iloc[:,:-1].values\n",
    "\n",
    "#2. Encoding categorical data\n",
    "X_b4_encode = bank_data_min.iloc[:,:-1].values\n",
    "ohe = OneHotEncoder()\n",
    "col_trans = ColumnTransformer(transformers= [('encoder',ohe,[0,1,2,3,4,5,6,7])])\n",
    "X_b4_encode = col_trans.fit_transform(X_b4_encode)\n",
    "X_b4_encode = pd.DataFrame(X_b4_encode.toarray())\n",
    "name_list = [string.replace(\"encoder__\",\"\") for string in col_trans.get_feature_names()]\n",
    "var_encoder = {'x0': 'job_type', 'x1': 'marital', 'x2': 'education', 'x3': 'has_credit', 'x4': 'has_house_loan', \\\n",
    "               'x5': 'has_person_loan', 'x6': 'contact', 'x7': 'prev_outcome'}\n",
    "name_list = [string.replace(string[:2],var_encoder[string[:2]]) for string in name_list]\n",
    "X_b4_encode.columns = name_list\n",
    "X = pd.concat([X_b4_encode,pd.DataFrame(X[:,8:])],axis=1)\n",
    "name_list.extend(['age', 'campaign', 'previous', 'emp_var_rate', 'cpi','cci', 'euribor3m'])\n",
    "X.columns = name_list\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "#3. Spliting data into training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "#4. Feature Scaling\n",
    "sc = StandardScaler()\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "X_train[:,38:] = sc.fit_transform(X_train[:,38:])\n",
    "X_test[:,38:] = sc.transform(X_test[:,38:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The approach is to train dataset using a Decision Tree and use obtained ranking of importance of the features to train ANN quicker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = ExtraTreesClassifier()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "model = SelectFromModel(clf, prefit=True)\n",
    "X_train_reduced = model.transform(X_train)\n",
    "feature_idx = model.get_support()\n",
    "feature_name = X.columns[feature_idx]\n",
    "X_test_reduced = X_test[:,feature_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_name)\n",
    "#Number of features we will be building the network with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Artificial Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there is no hard evidence or test to perform in order to find the exact number of layers and nodes for the ANN and there are only guidelines of how to do it, I will be experimenting with different combinations of those numbers. \n",
    "1. two hidden layers with 5 nodes each\n",
    "2. two hidden layers with 6 nodes and 4 nodes\n",
    "3. two hidden layers with 3 nodes each\n",
    "4. hidden layer with 6 nodes\n",
    "5. hidden layer with 4 nodes\n",
    "Accuracy will be checked using Confusion Matrix. For more elaborate accuracy rates please take a look at my previous project, that was mentioned at the very top.\n",
    "Activation function for hidden layer is a rectifier function, for output layer- sigmoid.\n",
    "Those functions are most common to use for binary dependent variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifierANN_1 = Sequential()\n",
    "classifierANN_2 = Sequential()\n",
    "classifierANN_3 = Sequential()\n",
    "classifierANN_4 = Sequential()\n",
    "classifierANN_5 = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifier 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Applications/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Applications/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "32950/32950 [==============================] - 2s 49us/sample - loss: 0.4555 - acc: 0.7988\n",
      "Epoch 2/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2947 - acc: 0.8893\n",
      "Epoch 3/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2875 - acc: 0.89520s - loss: 0.2877 - ETA: 0s - loss: 0.2863 - acc: 0.8\n",
      "Epoch 4/100\n",
      "32950/32950 [==============================] - 2s 47us/sample - loss: 0.2854 - acc: 0.8973\n",
      "Epoch 5/100\n",
      "32950/32950 [==============================] - 2s 50us/sample - loss: 0.2845 - acc: 0.89921s - loss - ETA: 0s - loss: 0.2843 - acc: 0\n",
      "Epoch 6/100\n",
      "32950/32950 [==============================] - 1s 38us/sample - loss: 0.2842 - acc: 0.8995\n",
      "Epoch 7/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2837 - acc: 0.8995\n",
      "Epoch 8/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2837 - acc: 0.8997\n",
      "Epoch 9/100\n",
      "32950/32950 [==============================] - 1s 36us/sample - loss: 0.2836 - acc: 0.9002\n",
      "Epoch 10/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2836 - acc: 0.8995\n",
      "Epoch 11/100\n",
      "32950/32950 [==============================] - 1s 38us/sample - loss: 0.2835 - acc: 0.8999\n",
      "Epoch 12/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2833 - acc: 0.8998\n",
      "Epoch 13/100\n",
      "32950/32950 [==============================] - 1s 38us/sample - loss: 0.2833 - acc: 0.8999\n",
      "Epoch 14/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2831 - acc: 0.8998\n",
      "Epoch 15/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2832 - acc: 0.8997\n",
      "Epoch 16/100\n",
      "32950/32950 [==============================] - 1s 36us/sample - loss: 0.2832 - acc: 0.8993\n",
      "Epoch 17/100\n",
      "32950/32950 [==============================] - 1s 38us/sample - loss: 0.2831 - acc: 0.9002\n",
      "Epoch 18/100\n",
      "32950/32950 [==============================] - 1s 38us/sample - loss: 0.2832 - acc: 0.8998\n",
      "Epoch 19/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2831 - acc: 0.8995\n",
      "Epoch 20/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2830 - acc: 0.90000s - loss: 0.2841 - acc: 0. - ETA: 0s - loss: 0.2833 - acc: 0.900\n",
      "Epoch 21/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2829 - acc: 0.8998\n",
      "Epoch 22/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2829 - acc: 0.89980s - loss: 0.2776 - a\n",
      "Epoch 23/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2828 - acc: 0.90000s - loss: 0.2819 - acc - ETA: 0s - loss: 0.2833 - acc: 0\n",
      "Epoch 24/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2828 - acc: 0.9000\n",
      "Epoch 25/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2827 - acc: 0.8996\n",
      "Epoch 26/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2826 - acc: 0.8995\n",
      "Epoch 27/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2827 - acc: 0.90030s - loss: 0.2834 - acc: 0\n",
      "Epoch 28/100\n",
      "32950/32950 [==============================] - 1s 36us/sample - loss: 0.2826 - acc: 0.9003\n",
      "Epoch 29/100\n",
      "32950/32950 [==============================] - 1s 38us/sample - loss: 0.2826 - acc: 0.90000s - loss: 0.2839 - acc:\n",
      "Epoch 30/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2823 - acc: 0.8997\n",
      "Epoch 31/100\n",
      "32950/32950 [==============================] - 1s 36us/sample - loss: 0.2825 - acc: 0.8998\n",
      "Epoch 32/100\n",
      "32950/32950 [==============================] - 1s 38us/sample - loss: 0.2824 - acc: 0.9002\n",
      "Epoch 33/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2823 - acc: 0.90000s - loss: 0.2829 - acc: 0.8\n",
      "Epoch 34/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2824 - acc: 0.8999\n",
      "Epoch 35/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2824 - acc: 0.9001\n",
      "Epoch 36/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2822 - acc: 0.8999\n",
      "Epoch 37/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2824 - acc: 0.89960s - loss: 0.2765 - a\n",
      "Epoch 38/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2821 - acc: 0.9001\n",
      "Epoch 39/100\n",
      "32950/32950 [==============================] - 1s 36us/sample - loss: 0.2823 - acc: 0.9001\n",
      "Epoch 40/100\n",
      "32950/32950 [==============================] - 1s 36us/sample - loss: 0.2820 - acc: 0.8998\n",
      "Epoch 41/100\n",
      "32950/32950 [==============================] - 1s 45us/sample - loss: 0.2821 - acc: 0.8998\n",
      "Epoch 42/100\n",
      "32950/32950 [==============================] - 2s 50us/sample - loss: 0.2823 - acc: 0.89980s - loss: 0.28\n",
      "Epoch 43/100\n",
      "32950/32950 [==============================] - 1s 43us/sample - loss: 0.2821 - acc: 0.9000\n",
      "Epoch 44/100\n",
      "32950/32950 [==============================] - 2s 67us/sample - loss: 0.2820 - acc: 0.90030s - loss: 0.\n",
      "Epoch 45/100\n",
      "32950/32950 [==============================] - 2s 63us/sample - loss: 0.2821 - acc: 0.89991s - loss: 0.2817 - - ETA: 0s - loss: 0.2816 - \n",
      "Epoch 46/100\n",
      "32950/32950 [==============================] - 1s 40us/sample - loss: 0.2820 - acc: 0.8999\n",
      "Epoch 47/100\n",
      "32950/32950 [==============================] - 1s 38us/sample - loss: 0.2819 - acc: 0.8998\n",
      "Epoch 48/100\n",
      "32950/32950 [==============================] - 1s 38us/sample - loss: 0.2817 - acc: 0.8998\n",
      "Epoch 49/100\n",
      "32950/32950 [==============================] - 1s 41us/sample - loss: 0.2821 - acc: 0.89980s - loss: 0\n",
      "Epoch 50/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2819 - acc: 0.9002\n",
      "Epoch 51/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2819 - acc: 0.8998\n",
      "Epoch 52/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2817 - acc: 0.90010s - loss: 0.2845 - acc: 0.899 - ETA: 0s - loss: 0.2841 - ac - ETA: 0s - loss: 0.2839 - acc: 0.89\n",
      "Epoch 53/100\n",
      "32950/32950 [==============================] - 1s 40us/sample - loss: 0.2819 - acc: 0.9001\n",
      "Epoch 54/100\n",
      "32950/32950 [==============================] - 1s 38us/sample - loss: 0.2818 - acc: 0.8997\n",
      "Epoch 55/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2817 - acc: 0.89990s - loss: 0.2820 - acc: 0.899\n",
      "Epoch 56/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2816 - acc: 0.9003\n",
      "Epoch 57/100\n",
      "32950/32950 [==============================] - 1s 44us/sample - loss: 0.2817 - acc: 0.9000\n",
      "Epoch 58/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2815 - acc: 0.90040s - loss: 0.2782\n",
      "Epoch 59/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2816 - acc: 0.8999\n",
      "Epoch 60/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2815 - acc: 0.89980s - loss: 0.2775 - - ETA: 0s - loss: 0.2797 - acc: 0.\n",
      "Epoch 61/100\n",
      "32950/32950 [==============================] - 1s 43us/sample - loss: 0.2814 - acc: 0.89980s - loss: 0.2818 - acc: 0.899 - ETA: 0s - loss: 0.2817 - acc: 0.899\n",
      "Epoch 62/100\n",
      "32950/32950 [==============================] - 2s 50us/sample - loss: 0.2815 - acc: 0.9001\n",
      "Epoch 63/100\n",
      "32950/32950 [==============================] - 1s 40us/sample - loss: 0.2814 - acc: 0.8998\n",
      "Epoch 64/100\n",
      "32950/32950 [==============================] - 1s 38us/sample - loss: 0.2813 - acc: 0.8998\n",
      "Epoch 65/100\n",
      "32950/32950 [==============================] - 1s 43us/sample - loss: 0.2813 - acc: 0.9001\n",
      "Epoch 66/100\n",
      "32950/32950 [==============================] - 1s 40us/sample - loss: 0.2812 - acc: 0.9000\n",
      "Epoch 67/100\n",
      "32950/32950 [==============================] - 1s 41us/sample - loss: 0.2813 - acc: 0.9002\n",
      "Epoch 68/100\n",
      "32950/32950 [==============================] - 1s 36us/sample - loss: 0.2812 - acc: 0.8998\n",
      "Epoch 69/100\n",
      "32950/32950 [==============================] - 1s 41us/sample - loss: 0.2810 - acc: 0.9002\n",
      "Epoch 70/100\n",
      "32950/32950 [==============================] - 1s 39us/sample - loss: 0.2811 - acc: 0.9003\n",
      "Epoch 71/100\n",
      "32950/32950 [==============================] - 1s 36us/sample - loss: 0.2812 - acc: 0.9003\n",
      "Epoch 72/100\n",
      "32950/32950 [==============================] - 1s 36us/sample - loss: 0.2812 - acc: 0.90040s - loss: 0.2860 - acc\n",
      "Epoch 73/100\n",
      "32950/32950 [==============================] - 1s 40us/sample - loss: 0.2812 - acc: 0.9003\n",
      "Epoch 74/100\n",
      "32950/32950 [==============================] - 1s 38us/sample - loss: 0.2811 - acc: 0.90040s - loss: 0.2740 - acc: 0.903 - ETA: 0s - loss: 0.2745 -\n",
      "Epoch 75/100\n",
      "32950/32950 [==============================] - 1s 39us/sample - loss: 0.2811 - acc: 0.90010s - loss: 0.2812 - acc: 0\n",
      "Epoch 76/100\n",
      "32950/32950 [==============================] - 1s 36us/sample - loss: 0.2812 - acc: 0.9002\n",
      "Epoch 77/100\n",
      "32950/32950 [==============================] - 1s 40us/sample - loss: 0.2811 - acc: 0.9001\n",
      "Epoch 78/100\n",
      "32950/32950 [==============================] - 1s 36us/sample - loss: 0.2811 - acc: 0.9001\n",
      "Epoch 79/100\n",
      "32950/32950 [==============================] - 1s 36us/sample - loss: 0.2810 - acc: 0.9002\n",
      "Epoch 80/100\n",
      "32950/32950 [==============================] - 1s 39us/sample - loss: 0.2811 - acc: 0.90030s - loss:\n",
      "Epoch 81/100\n",
      "32950/32950 [==============================] - 1s 42us/sample - loss: 0.2811 - acc: 0.89980s - loss: 0.2790 - acc: 0.90 - ETA: 0s - loss: 0.2796 - acc: 0.\n",
      "Epoch 82/100\n",
      "32950/32950 [==============================] - 1s 38us/sample - loss: 0.2810 - acc: 0.9001\n",
      "Epoch 83/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2809 - acc: 0.9002\n",
      "Epoch 84/100\n",
      "32950/32950 [==============================] - 1s 36us/sample - loss: 0.2810 - acc: 0.90030s - loss: 0.2786 - ac\n",
      "Epoch 85/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2810 - acc: 0.9004\n",
      "Epoch 86/100\n",
      "32950/32950 [==============================] - 1s 40us/sample - loss: 0.2811 - acc: 0.9001\n",
      "Epoch 87/100\n",
      "32950/32950 [==============================] - 1s 38us/sample - loss: 0.2809 - acc: 0.9002\n",
      "Epoch 88/100\n",
      "32950/32950 [==============================] - 1s 36us/sample - loss: 0.2809 - acc: 0.9000\n",
      "Epoch 89/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2809 - acc: 0.9001\n",
      "Epoch 90/100\n",
      "32950/32950 [==============================] - 2s 46us/sample - loss: 0.2808 - acc: 0.9003\n",
      "Epoch 91/100\n",
      "32950/32950 [==============================] - 1s 40us/sample - loss: 0.2810 - acc: 0.9002\n",
      "Epoch 92/100\n",
      "32950/32950 [==============================] - 2s 51us/sample - loss: 0.2809 - acc: 0.9002\n",
      "Epoch 93/100\n",
      "32950/32950 [==============================] - 1s 44us/sample - loss: 0.2810 - acc: 0.90010s - loss: 0.280\n",
      "Epoch 94/100\n",
      "32950/32950 [==============================] - 1s 43us/sample - loss: 0.2809 - acc: 0.90020s - loss: 0.2821 - acc: 0.89\n",
      "Epoch 95/100\n",
      "32950/32950 [==============================] - 1s 43us/sample - loss: 0.2808 - acc: 0.9003\n",
      "Epoch 96/100\n",
      "32950/32950 [==============================] - 1s 38us/sample - loss: 0.2810 - acc: 0.90030s - loss: 0.2820 - acc: 0.9\n",
      "Epoch 97/100\n",
      "32950/32950 [==============================] - 1s 38us/sample - loss: 0.2810 - acc: 0.9003\n",
      "Epoch 98/100\n",
      "32950/32950 [==============================] - 1s 38us/sample - loss: 0.2809 - acc: 0.9001\n",
      "Epoch 99/100\n",
      "32950/32950 [==============================] - 1s 38us/sample - loss: 0.2809 - acc: 0.9001\n",
      "Epoch 100/100\n",
      "32950/32950 [==============================] - 1s 35us/sample - loss: 0.2809 - acc: 0.8998\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a4adb9dd0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Input layer and 1st hidden layer\n",
    "classifierANN_1.add(Dense(5, activation = 'relu'))\n",
    "#2nd hidden layer\n",
    "classifierANN_1.add(Dense(5, activation = 'relu'))\n",
    "#Output layer\n",
    "classifierANN_1.add(Dense(1, activation = 'sigmoid'))\n",
    "#Compilion the ANN\n",
    "classifierANN_1.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "#Fitting classifier to the training set \n",
    "classifierANN_1.fit(X_train_reduced, y_train, batch_size=32, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting y value\n",
    "y_pred = classifierANN_1.predict(X_test_reduced)\n",
    "y_pred = (y_pred>0.5)\n",
    "\n",
    "#Checking accuracy score\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "acc_1 = accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifier 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "32950/32950 [==============================] - 1s 45us/sample - loss: 0.3654 - acc: 0.8775\n",
      "Epoch 2/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2941 - acc: 0.88781s - loss: 0.282 - ETA: 0s - loss: 0.2934 - acc:\n",
      "Epoch 3/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2918 - acc: 0.8878\n",
      "Epoch 4/100\n",
      "32950/32950 [==============================] - 2s 50us/sample - loss: 0.2900 - acc: 0.8878\n",
      "Epoch 5/100\n",
      "32950/32950 [==============================] - 1s 45us/sample - loss: 0.2884 - acc: 0.8934\n",
      "Epoch 6/100\n",
      "32950/32950 [==============================] - 2s 46us/sample - loss: 0.2870 - acc: 0.8983\n",
      "Epoch 7/100\n",
      "32950/32950 [==============================] - 2s 51us/sample - loss: 0.2857 - acc: 0.8985\n",
      "Epoch 8/100\n",
      "32950/32950 [==============================] - 1s 44us/sample - loss: 0.2844 - acc: 0.89860s - loss: 0.2747 - acc - ETA: 0s - loss: 0.2835 - ac\n",
      "Epoch 9/100\n",
      "32950/32950 [==============================] - 1s 43us/sample - loss: 0.2835 - acc: 0.8991\n",
      "Epoch 10/100\n",
      "32950/32950 [==============================] - 1s 44us/sample - loss: 0.2827 - acc: 0.89920s - loss: 0\n",
      "Epoch 11/100\n",
      "32950/32950 [==============================] - 2s 47us/sample - loss: 0.2823 - acc: 0.89911s - l\n",
      "Epoch 12/100\n",
      "32950/32950 [==============================] - 1s 38us/sample - loss: 0.2818 - acc: 0.89940s - loss: 0.2819 - acc: 0.899\n",
      "Epoch 13/100\n",
      "32950/32950 [==============================] - 1s 38us/sample - loss: 0.2815 - acc: 0.8993\n",
      "Epoch 14/100\n",
      "32950/32950 [==============================] - 1s 39us/sample - loss: 0.2813 - acc: 0.8991\n",
      "Epoch 15/100\n",
      "32950/32950 [==============================] - 1s 38us/sample - loss: 0.2812 - acc: 0.89960s - loss: 0.2771 - acc: 0 - ETA: 0s - loss: 0.2772 \n",
      "Epoch 16/100\n",
      "32950/32950 [==============================] - 1s 38us/sample - loss: 0.2808 - acc: 0.89920s - loss: 0.285\n",
      "Epoch 17/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2807 - acc: 0.89980s - loss: 0.2808 - acc: 0\n",
      "Epoch 18/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2806 - acc: 0.8994\n",
      "Epoch 19/100\n",
      "32950/32950 [==============================] - 1s 39us/sample - loss: 0.2804 - acc: 0.89960s - loss: 0.2\n",
      "Epoch 20/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2802 - acc: 0.8993\n",
      "Epoch 21/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2800 - acc: 0.8997\n",
      "Epoch 22/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2800 - acc: 0.8997\n",
      "Epoch 23/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2802 - acc: 0.8995\n",
      "Epoch 24/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2799 - acc: 0.90020s - loss: 0.2755 - ETA: 0s - loss: 0.2815 - acc: 0.8\n",
      "Epoch 25/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2797 - acc: 0.9001\n",
      "Epoch 26/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2795 - acc: 0.8998\n",
      "Epoch 27/100\n",
      "32950/32950 [==============================] - 1s 38us/sample - loss: 0.2798 - acc: 0.8998\n",
      "Epoch 28/100\n",
      "32950/32950 [==============================] - 2s 54us/sample - loss: 0.2797 - acc: 0.89980s - loss: 0.2767 - acc: 0 - ETA: 0s - loss: 0.2785 - ac\n",
      "Epoch 29/100\n",
      "32950/32950 [==============================] - 2s 53us/sample - loss: 0.2795 - acc: 0.8992\n",
      "Epoch 30/100\n",
      "32950/32950 [==============================] - 1s 45us/sample - loss: 0.2795 - acc: 0.8999\n",
      "Epoch 31/100\n",
      "32950/32950 [==============================] - 1s 41us/sample - loss: 0.2796 - acc: 0.90011s - loss: 0\n",
      "Epoch 32/100\n",
      "32950/32950 [==============================] - 1s 43us/sample - loss: 0.2795 - acc: 0.8992\n",
      "Epoch 33/100\n",
      "32950/32950 [==============================] - 1s 41us/sample - loss: 0.2793 - acc: 0.89971s - loss: 0.2585 - acc: 0.908 - ETA: 1s - loss:\n",
      "Epoch 34/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2792 - acc: 0.90000s - loss: 0.27\n",
      "Epoch 35/100\n",
      "32950/32950 [==============================] - 1s 38us/sample - loss: 0.2794 - acc: 0.8992\n",
      "Epoch 36/100\n",
      "32950/32950 [==============================] - 1s 38us/sample - loss: 0.2794 - acc: 0.8996\n",
      "Epoch 37/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2792 - acc: 0.89960s - loss: 0.280\n",
      "Epoch 38/100\n",
      "32950/32950 [==============================] - 1s 40us/sample - loss: 0.2793 - acc: 0.9002\n",
      "Epoch 39/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2792 - acc: 0.8998\n",
      "Epoch 40/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2792 - acc: 0.8998\n",
      "Epoch 41/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2793 - acc: 0.90030s - loss: 0.284\n",
      "Epoch 42/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2792 - acc: 0.9001\n",
      "Epoch 43/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2791 - acc: 0.8995\n",
      "Epoch 44/100\n",
      "32950/32950 [==============================] - 1s 36us/sample - loss: 0.2791 - acc: 0.8997\n",
      "Epoch 45/100\n",
      "32950/32950 [==============================] - 1s 38us/sample - loss: 0.2791 - acc: 0.89970s - loss: 0.2835 - acc: 0.8 - ETA: 0s - loss: 0.2806 -\n",
      "Epoch 46/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2791 - acc: 0.89970s - loss: 0.2776 - acc:\n",
      "Epoch 47/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2788 - acc: 0.90000s - loss: 0.2837 - a\n",
      "Epoch 48/100\n",
      "32950/32950 [==============================] - 1s 38us/sample - loss: 0.2790 - acc: 0.90000s - loss: 0.28\n",
      "Epoch 49/100\n",
      "32950/32950 [==============================] - 1s 38us/sample - loss: 0.2789 - acc: 0.8997\n",
      "Epoch 50/100\n",
      "32950/32950 [==============================] - 2s 50us/sample - loss: 0.2789 - acc: 0.8992\n",
      "Epoch 51/100\n",
      "32950/32950 [==============================] - 2s 59us/sample - loss: 0.2789 - acc: 0.8998\n",
      "Epoch 52/100\n",
      "32950/32950 [==============================] - 2s 65us/sample - loss: 0.2790 - acc: 0.8999\n",
      "Epoch 53/100\n",
      "32950/32950 [==============================] - 1s 41us/sample - loss: 0.2787 - acc: 0.8998\n",
      "Epoch 54/100\n",
      "32950/32950 [==============================] - 1s 39us/sample - loss: 0.2788 - acc: 0.8993\n",
      "Epoch 55/100\n",
      "32950/32950 [==============================] - 1s 38us/sample - loss: 0.2788 - acc: 0.9000\n",
      "Epoch 56/100\n",
      "32950/32950 [==============================] - 2s 49us/sample - loss: 0.2787 - acc: 0.89990s - loss: 0.2\n",
      "Epoch 57/100\n",
      "32950/32950 [==============================] - 2s 68us/sample - loss: 0.2786 - acc: 0.8998\n",
      "Epoch 58/100\n",
      "32950/32950 [==============================] - 2s 74us/sample - loss: 0.2786 - acc: 0.90040s - loss:\n",
      "Epoch 59/100\n",
      "32950/32950 [==============================] - 2s 51us/sample - loss: 0.2787 - acc: 0.90001s - loss: 0 - ETA: 0s - loss: 0.2788 - acc: 0.\n",
      "Epoch 60/100\n",
      "32950/32950 [==============================] - 1s 38us/sample - loss: 0.2788 - acc: 0.9000\n",
      "Epoch 61/100\n",
      "32950/32950 [==============================] - 1s 41us/sample - loss: 0.2784 - acc: 0.8999\n",
      "Epoch 62/100\n",
      "32950/32950 [==============================] - 2s 56us/sample - loss: 0.2786 - acc: 0.8995\n",
      "Epoch 63/100\n",
      "32950/32950 [==============================] - 1s 44us/sample - loss: 0.2787 - acc: 0.89980s - loss: 0.\n",
      "Epoch 64/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2785 - acc: 0.8997\n",
      "Epoch 65/100\n",
      "32950/32950 [==============================] - 1s 41us/sample - loss: 0.2785 - acc: 0.8999\n",
      "Epoch 66/100\n",
      "32950/32950 [==============================] - 1s 39us/sample - loss: 0.2783 - acc: 0.8998\n",
      "Epoch 67/100\n",
      "32950/32950 [==============================] - 1s 45us/sample - loss: 0.2785 - acc: 0.9001\n",
      "Epoch 68/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2783 - acc: 0.8995\n",
      "Epoch 69/100\n",
      "32950/32950 [==============================] - 1s 43us/sample - loss: 0.2786 - acc: 0.89950s - loss: 0.2789 - acc: 0.89\n",
      "Epoch 70/100\n",
      "32950/32950 [==============================] - 1s 39us/sample - loss: 0.2784 - acc: 0.9006\n",
      "Epoch 71/100\n",
      "32950/32950 [==============================] - 2s 51us/sample - loss: 0.2784 - acc: 0.89951s - loss: 0.2807 - acc: 0.89 - ETA: 1s -\n",
      "Epoch 72/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2785 - acc: 0.9002\n",
      "Epoch 73/100\n",
      "32950/32950 [==============================] - 1s 40us/sample - loss: 0.2785 - acc: 0.9000\n",
      "Epoch 74/100\n",
      "32950/32950 [==============================] - 2s 47us/sample - loss: 0.2783 - acc: 0.9002\n",
      "Epoch 75/100\n",
      "32950/32950 [==============================] - 2s 48us/sample - loss: 0.2783 - acc: 0.9004\n",
      "Epoch 76/100\n",
      "32950/32950 [==============================] - 1s 40us/sample - loss: 0.2783 - acc: 0.9004\n",
      "Epoch 77/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2785 - acc: 0.9003\n",
      "Epoch 78/100\n",
      "32950/32950 [==============================] - 1s 43us/sample - loss: 0.2783 - acc: 0.8999\n",
      "Epoch 79/100\n",
      "32950/32950 [==============================] - 1s 38us/sample - loss: 0.2783 - acc: 0.9002\n",
      "Epoch 80/100\n",
      "32950/32950 [==============================] - 1s 41us/sample - loss: 0.2784 - acc: 0.9005\n",
      "Epoch 81/100\n",
      "32950/32950 [==============================] - 1s 38us/sample - loss: 0.2782 - acc: 0.9002\n",
      "Epoch 82/100\n",
      "32950/32950 [==============================] - 1s 43us/sample - loss: 0.2782 - acc: 0.89970s - loss: 0.2774 -\n",
      "Epoch 83/100\n",
      "32950/32950 [==============================] - 1s 44us/sample - loss: 0.2782 - acc: 0.9002\n",
      "Epoch 84/100\n",
      "32950/32950 [==============================] - 2s 61us/sample - loss: 0.2782 - acc: 0.8999\n",
      "Epoch 85/100\n",
      "32950/32950 [==============================] - 1s 45us/sample - loss: 0.2782 - acc: 0.90021s - lo\n",
      "Epoch 86/100\n",
      "32950/32950 [==============================] - 2s 48us/sample - loss: 0.2782 - acc: 0.90020s - loss: 0.2789 - acc: 0.89\n",
      "Epoch 87/100\n",
      "32950/32950 [==============================] - 2s 63us/sample - loss: 0.2780 - acc: 0.9006\n",
      "Epoch 88/100\n",
      "32950/32950 [==============================] - 1s 40us/sample - loss: 0.2782 - acc: 0.9000\n",
      "Epoch 89/100\n",
      "32950/32950 [==============================] - 2s 51us/sample - loss: 0.2781 - acc: 0.9000\n",
      "Epoch 90/100\n",
      "32950/32950 [==============================] - 2s 61us/sample - loss: 0.2781 - acc: 0.90001s - loss: \n",
      "Epoch 91/100\n",
      "32950/32950 [==============================] - 2s 74us/sample - loss: 0.2782 - acc: 0.89980s - loss: 0.2810 \n",
      "Epoch 92/100\n",
      "32950/32950 [==============================] - 2s 49us/sample - loss: 0.2782 - acc: 0.9004\n",
      "Epoch 93/100\n",
      "32950/32950 [==============================] - 1s 44us/sample - loss: 0.2782 - acc: 0.89970s - loss: 0.2750 -\n",
      "Epoch 94/100\n",
      "32950/32950 [==============================] - 1s 40us/sample - loss: 0.2780 - acc: 0.89980s - loss: 0.\n",
      "Epoch 95/100\n",
      "32950/32950 [==============================] - 2s 47us/sample - loss: 0.2781 - acc: 0.8997\n",
      "Epoch 96/100\n",
      "32950/32950 [==============================] - 2s 47us/sample - loss: 0.2780 - acc: 0.9001\n",
      "Epoch 97/100\n",
      "32950/32950 [==============================] - 2s 50us/sample - loss: 0.2781 - acc: 0.89980s - loss: 0.\n",
      "Epoch 98/100\n",
      "32950/32950 [==============================] - 1s 42us/sample - loss: 0.2782 - acc: 0.9001\n",
      "Epoch 99/100\n",
      "32950/32950 [==============================] - 1s 43us/sample - loss: 0.2782 - acc: 0.89980s - loss: 0.2794 - acc: 0.\n",
      "Epoch 100/100\n",
      "32950/32950 [==============================] - 2s 46us/sample - loss: 0.2781 - acc: 0.89980s - loss: 0.2778 - acc: 0.90\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a4b2dbdd0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Input layer and 1st hidden layer\n",
    "classifierANN_2.add(Dense(6, activation = 'relu'))\n",
    "#2nd hidden layer\n",
    "classifierANN_2.add(Dense(4, activation = 'relu'))\n",
    "#Output layer\n",
    "classifierANN_2.add(Dense(1, activation = 'sigmoid'))\n",
    "#Compilion the ANN\n",
    "classifierANN_2.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "#Fitting classifier to the training set \n",
    "classifierANN_2.fit(X_train_reduced, y_train, batch_size=32, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting y value\n",
    "y_pred = classifierANN_2.predict(X_test_reduced)\n",
    "y_pred = (y_pred>0.5)\n",
    "\n",
    "#Checking accuracy score\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "acc_2 = accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifier 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "32950/32950 [==============================] - 2s 53us/sample - loss: 0.4325 - acc: 0.8646\n",
      "Epoch 2/100\n",
      "32950/32950 [==============================] - 1s 43us/sample - loss: 0.3135 - acc: 0.8878\n",
      "Epoch 3/100\n",
      "32950/32950 [==============================] - 2s 46us/sample - loss: 0.2998 - acc: 0.8878\n",
      "Epoch 4/100\n",
      "32950/32950 [==============================] - 1s 40us/sample - loss: 0.2950 - acc: 0.88780s - loss: 0.2954 - acc: 0.88\n",
      "Epoch 5/100\n",
      "32950/32950 [==============================] - 1s 40us/sample - loss: 0.2934 - acc: 0.88780s - loss: 0.30\n",
      "Epoch 6/100\n",
      "32950/32950 [==============================] - 1s 44us/sample - loss: 0.2921 - acc: 0.8878\n",
      "Epoch 7/100\n",
      "32950/32950 [==============================] - 1s 39us/sample - loss: 0.2912 - acc: 0.8878\n",
      "Epoch 8/100\n",
      "32950/32950 [==============================] - 1s 40us/sample - loss: 0.2906 - acc: 0.8888\n",
      "Epoch 9/100\n",
      "32950/32950 [==============================] - 1s 39us/sample - loss: 0.2901 - acc: 0.8909\n",
      "Epoch 10/100\n",
      "32950/32950 [==============================] - 2s 46us/sample - loss: 0.2897 - acc: 0.89300s - loss: 0\n",
      "Epoch 11/100\n",
      "32950/32950 [==============================] - 1s 40us/sample - loss: 0.2895 - acc: 0.8935\n",
      "Epoch 12/100\n",
      "32950/32950 [==============================] - 1s 42us/sample - loss: 0.2893 - acc: 0.8937\n",
      "Epoch 13/100\n",
      "32950/32950 [==============================] - 2s 47us/sample - loss: 0.2889 - acc: 0.89410s - loss: \n",
      "Epoch 14/100\n",
      "32950/32950 [==============================] - 1s 38us/sample - loss: 0.2888 - acc: 0.89411s - loss: \n",
      "Epoch 15/100\n",
      "32950/32950 [==============================] - 1s 41us/sample - loss: 0.2885 - acc: 0.8945\n",
      "Epoch 16/100\n",
      "32950/32950 [==============================] - 1s 45us/sample - loss: 0.2882 - acc: 0.89640s - loss: 0.2900 - acc: 0.89 - ETA: 0s - loss: 0.2888 - acc: 0.\n",
      "Epoch 17/100\n",
      "32950/32950 [==============================] - 1s 41us/sample - loss: 0.2880 - acc: 0.8966\n",
      "Epoch 18/100\n",
      "32950/32950 [==============================] - 1s 42us/sample - loss: 0.2878 - acc: 0.8980\n",
      "Epoch 19/100\n",
      "32950/32950 [==============================] - 1s 41us/sample - loss: 0.2876 - acc: 0.8977\n",
      "Epoch 20/100\n",
      "32950/32950 [==============================] - 1s 39us/sample - loss: 0.2873 - acc: 0.8982\n",
      "Epoch 21/100\n",
      "32950/32950 [==============================] - 2s 46us/sample - loss: 0.2872 - acc: 0.8982\n",
      "Epoch 22/100\n",
      "32950/32950 [==============================] - 2s 51us/sample - loss: 0.2870 - acc: 0.8981\n",
      "Epoch 23/100\n",
      "32950/32950 [==============================] - 1s 40us/sample - loss: 0.2870 - acc: 0.8982\n",
      "Epoch 24/100\n",
      "32950/32950 [==============================] - 1s 38us/sample - loss: 0.2868 - acc: 0.8986\n",
      "Epoch 25/100\n",
      "32950/32950 [==============================] - 1s 41us/sample - loss: 0.2867 - acc: 0.8987\n",
      "Epoch 26/100\n",
      "32950/32950 [==============================] - 2s 57us/sample - loss: 0.2867 - acc: 0.89880s - loss: 0.287\n",
      "Epoch 27/100\n",
      "32950/32950 [==============================] - 2s 53us/sample - loss: 0.2866 - acc: 0.8988\n",
      "Epoch 28/100\n",
      "32950/32950 [==============================] - 2s 54us/sample - loss: 0.2865 - acc: 0.8990\n",
      "Epoch 29/100\n",
      "32950/32950 [==============================] - 2s 49us/sample - loss: 0.2863 - acc: 0.8985\n",
      "Epoch 30/100\n",
      "32950/32950 [==============================] - 2s 54us/sample - loss: 0.2862 - acc: 0.8986\n",
      "Epoch 31/100\n",
      "32950/32950 [==============================] - 2s 48us/sample - loss: 0.2862 - acc: 0.8990\n",
      "Epoch 32/100\n",
      "32950/32950 [==============================] - 1s 40us/sample - loss: 0.2862 - acc: 0.8988\n",
      "Epoch 33/100\n",
      "32950/32950 [==============================] - 1s 42us/sample - loss: 0.2861 - acc: 0.8986\n",
      "Epoch 34/100\n",
      "32950/32950 [==============================] - 1s 42us/sample - loss: 0.2860 - acc: 0.89850s - loss: 0.29\n",
      "Epoch 35/100\n",
      "32950/32950 [==============================] - 1s 45us/sample - loss: 0.2860 - acc: 0.89860s - loss: 0.2\n",
      "Epoch 36/100\n",
      "32950/32950 [==============================] - 2s 67us/sample - loss: 0.2858 - acc: 0.8988\n",
      "Epoch 37/100\n",
      "32950/32950 [==============================] - 2s 61us/sample - loss: 0.2859 - acc: 0.8990\n",
      "Epoch 38/100\n",
      "32950/32950 [==============================] - 1s 40us/sample - loss: 0.2857 - acc: 0.8991\n",
      "Epoch 39/100\n",
      "32950/32950 [==============================] - 1s 41us/sample - loss: 0.2857 - acc: 0.8989\n",
      "Epoch 40/100\n",
      "32950/32950 [==============================] - 1s 41us/sample - loss: 0.2855 - acc: 0.8990\n",
      "Epoch 41/100\n",
      "32950/32950 [==============================] - 2s 51us/sample - loss: 0.2856 - acc: 0.8994\n",
      "Epoch 42/100\n",
      "32950/32950 [==============================] - 2s 61us/sample - loss: 0.2856 - acc: 0.8993\n",
      "Epoch 43/100\n",
      "32950/32950 [==============================] - 2s 46us/sample - loss: 0.2853 - acc: 0.89940s - loss: 0.2849 - acc: 0.899\n",
      "Epoch 44/100\n",
      "32950/32950 [==============================] - 1s 43us/sample - loss: 0.2848 - acc: 0.8993\n",
      "Epoch 45/100\n",
      "32950/32950 [==============================] - 1s 38us/sample - loss: 0.2848 - acc: 0.8997\n",
      "Epoch 46/100\n",
      "32950/32950 [==============================] - 2s 47us/sample - loss: 0.2839 - acc: 0.8994\n",
      "Epoch 47/100\n",
      "32950/32950 [==============================] - 1s 41us/sample - loss: 0.2830 - acc: 0.8996\n",
      "Epoch 48/100\n",
      "32950/32950 [==============================] - 1s 44us/sample - loss: 0.2826 - acc: 0.8992\n",
      "Epoch 49/100\n",
      "32950/32950 [==============================] - 1s 42us/sample - loss: 0.2820 - acc: 0.89960s - loss: 0\n",
      "Epoch 50/100\n",
      "32950/32950 [==============================] - 2s 55us/sample - loss: 0.2815 - acc: 0.8988\n",
      "Epoch 51/100\n",
      "32950/32950 [==============================] - 3s 80us/sample - loss: 0.2813 - acc: 0.8988\n",
      "Epoch 52/100\n",
      "32950/32950 [==============================] - 2s 64us/sample - loss: 0.2812 - acc: 0.89901s - loss: 0.2880 - acc: 0.894 - ETA: 1s - loss: 0.2900  - ETA: 0s - loss\n",
      "Epoch 53/100\n",
      "32950/32950 [==============================] - 2s 62us/sample - loss: 0.2810 - acc: 0.8984\n",
      "Epoch 54/100\n",
      "32950/32950 [==============================] - 2s 53us/sample - loss: 0.2807 - acc: 0.8985\n",
      "Epoch 55/100\n",
      "32950/32950 [==============================] - 1s 40us/sample - loss: 0.2806 - acc: 0.89860s - loss: 0.2\n",
      "Epoch 56/100\n",
      "32950/32950 [==============================] - 1s 40us/sample - loss: 0.2805 - acc: 0.89840s - loss: 0.2820 - ac\n",
      "Epoch 57/100\n",
      "32950/32950 [==============================] - 1s 44us/sample - loss: 0.2803 - acc: 0.8985\n",
      "Epoch 58/100\n",
      "32950/32950 [==============================] - 1s 43us/sample - loss: 0.2803 - acc: 0.89821s - loss: 0.2844 - acc:  - ETA: 0s - loss: 0.2831\n",
      "Epoch 59/100\n",
      "32950/32950 [==============================] - 1s 41us/sample - loss: 0.2803 - acc: 0.8982\n",
      "Epoch 60/100\n",
      "32950/32950 [==============================] - 1s 40us/sample - loss: 0.2802 - acc: 0.8984\n",
      "Epoch 61/100\n",
      "32950/32950 [==============================] - 1s 44us/sample - loss: 0.2802 - acc: 0.8983\n",
      "Epoch 62/100\n",
      "32950/32950 [==============================] - 1s 43us/sample - loss: 0.2802 - acc: 0.89841s - loss: 0.2856 - acc - ETA: 0s - loss: 0.2805 - acc:  - ETA: 0s - loss: 0.2818 - ac\n",
      "Epoch 63/100\n",
      "32950/32950 [==============================] - 1s 43us/sample - loss: 0.2802 - acc: 0.8984\n",
      "Epoch 64/100\n",
      "32950/32950 [==============================] - 1s 41us/sample - loss: 0.2800 - acc: 0.89830s - loss: 0.2777 \n",
      "Epoch 65/100\n",
      "32950/32950 [==============================] - 1s 45us/sample - loss: 0.2801 - acc: 0.89841s - los\n",
      "Epoch 66/100\n",
      "32950/32950 [==============================] - 1s 39us/sample - loss: 0.2802 - acc: 0.89800s - loss: 0.2818 - acc: 0.8\n",
      "Epoch 67/100\n",
      "32950/32950 [==============================] - 1s 39us/sample - loss: 0.2800 - acc: 0.8983\n",
      "Epoch 68/100\n",
      "32950/32950 [==============================] - 1s 45us/sample - loss: 0.2802 - acc: 0.8981\n",
      "Epoch 69/100\n",
      "32950/32950 [==============================] - 1s 41us/sample - loss: 0.2800 - acc: 0.8984\n",
      "Epoch 70/100\n",
      "32950/32950 [==============================] - 2s 46us/sample - loss: 0.2801 - acc: 0.8985\n",
      "Epoch 71/100\n",
      "32950/32950 [==============================] - 1s 41us/sample - loss: 0.2799 - acc: 0.8981\n",
      "Epoch 72/100\n",
      "32950/32950 [==============================] - 1s 44us/sample - loss: 0.2799 - acc: 0.8984\n",
      "Epoch 73/100\n",
      "32950/32950 [==============================] - 1s 40us/sample - loss: 0.2800 - acc: 0.89830s - loss: 0\n",
      "Epoch 74/100\n",
      "32950/32950 [==============================] - 2s 46us/sample - loss: 0.2801 - acc: 0.89831s - l\n",
      "Epoch 75/100\n",
      "32950/32950 [==============================] - 1s 44us/sample - loss: 0.2800 - acc: 0.8983\n",
      "Epoch 76/100\n",
      "32950/32950 [==============================] - 2s 47us/sample - loss: 0.2799 - acc: 0.8983\n",
      "Epoch 77/100\n",
      "32950/32950 [==============================] - 2s 53us/sample - loss: 0.2801 - acc: 0.8981\n",
      "Epoch 78/100\n",
      "32950/32950 [==============================] - 2s 46us/sample - loss: 0.2800 - acc: 0.8983\n",
      "Epoch 79/100\n",
      "32950/32950 [==============================] - 2s 53us/sample - loss: 0.2799 - acc: 0.8981\n",
      "Epoch 80/100\n",
      "32950/32950 [==============================] - 2s 60us/sample - loss: 0.2802 - acc: 0.8985\n",
      "Epoch 81/100\n",
      "32950/32950 [==============================] - 1s 40us/sample - loss: 0.2801 - acc: 0.8979\n",
      "Epoch 82/100\n",
      "32950/32950 [==============================] - 1s 42us/sample - loss: 0.2797 - acc: 0.8984\n",
      "Epoch 83/100\n",
      "32950/32950 [==============================] - 1s 43us/sample - loss: 0.2799 - acc: 0.8983\n",
      "Epoch 84/100\n",
      "32950/32950 [==============================] - 1s 43us/sample - loss: 0.2798 - acc: 0.8985\n",
      "Epoch 85/100\n",
      "32950/32950 [==============================] - 1s 42us/sample - loss: 0.2800 - acc: 0.8980\n",
      "Epoch 86/100\n",
      "32950/32950 [==============================] - 2s 47us/sample - loss: 0.2800 - acc: 0.89860s - loss: 0.2\n",
      "Epoch 87/100\n",
      "32950/32950 [==============================] - 1s 42us/sample - loss: 0.2798 - acc: 0.8984\n",
      "Epoch 88/100\n",
      "32950/32950 [==============================] - 1s 40us/sample - loss: 0.2802 - acc: 0.89811s - loss\n",
      "Epoch 89/100\n",
      "32950/32950 [==============================] - 1s 42us/sample - loss: 0.2799 - acc: 0.8982\n",
      "Epoch 90/100\n",
      "32950/32950 [==============================] - 1s 43us/sample - loss: 0.2800 - acc: 0.8982\n",
      "Epoch 91/100\n",
      "32950/32950 [==============================] - 1s 43us/sample - loss: 0.2798 - acc: 0.8981\n",
      "Epoch 92/100\n",
      "32950/32950 [==============================] - 1s 44us/sample - loss: 0.2798 - acc: 0.89810s - loss: \n",
      "Epoch 93/100\n",
      "32950/32950 [==============================] - 1s 42us/sample - loss: 0.2799 - acc: 0.8982\n",
      "Epoch 94/100\n",
      "32950/32950 [==============================] - 2s 49us/sample - loss: 0.2800 - acc: 0.89850s - loss: 0.2810 - acc: 0.89 - ETA: 0s - loss: 0.2822 - ac\n",
      "Epoch 95/100\n",
      "32950/32950 [==============================] - 1s 40us/sample - loss: 0.2798 - acc: 0.89810s - loss: 0.2804 - acc: 0.89\n",
      "Epoch 96/100\n",
      "32950/32950 [==============================] - 1s 41us/sample - loss: 0.2799 - acc: 0.8985\n",
      "Epoch 97/100\n",
      "32950/32950 [==============================] - 1s 41us/sample - loss: 0.2799 - acc: 0.89830s - loss: 0.2830 - acc: 0.89 - ETA: 0s - loss: 0.2820 - acc\n",
      "Epoch 98/100\n",
      "32950/32950 [==============================] - 1s 41us/sample - loss: 0.2797 - acc: 0.89820s - loss: 0.2804 - acc: 0.897\n",
      "Epoch 99/100\n",
      "32950/32950 [==============================] - 1s 42us/sample - loss: 0.2800 - acc: 0.89820s - loss: \n",
      "Epoch 100/100\n",
      "32950/32950 [==============================] - 1s 42us/sample - loss: 0.2799 - acc: 0.89850s - loss: 0.2795 - \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a4bdf9410>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Input layer and 1st hidden layer\n",
    "classifierANN_3.add(Dense(3, activation = 'relu'))\n",
    "#2nd hidden layer\n",
    "classifierANN_3.add(Dense(3, activation = 'relu'))\n",
    "#Output layer\n",
    "classifierANN_3.add(Dense(1, activation = 'sigmoid'))\n",
    "#Compilion the ANN\n",
    "classifierANN_3.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "#Fitting classifier to the training set \n",
    "classifierANN_3.fit(X_train_reduced, y_train, batch_size=32, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting y value\n",
    "y_pred = classifierANN_3.predict(X_test_reduced)\n",
    "y_pred = (y_pred>0.5)\n",
    "\n",
    "#Checking accuracy score\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "acc_3 = accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifier 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "32950/32950 [==============================] - 1s 43us/sample - loss: 0.4207 - acc: 0.82361s - loss: 0.\n",
      "Epoch 2/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2915 - acc: 0.89560s - loss: 0.2913 - acc: 0.895 - ETA: 0s - loss: 0.2926 - acc: \n",
      "Epoch 3/100\n",
      "32950/32950 [==============================] - 2s 55us/sample - loss: 0.2877 - acc: 0.89660s - loss: 0.2900 - acc: \n",
      "Epoch 4/100\n",
      "32950/32950 [==============================] - 1s 45us/sample - loss: 0.2860 - acc: 0.89901s - loss: 0\n",
      "Epoch 5/100\n",
      "32950/32950 [==============================] - 1s 38us/sample - loss: 0.2849 - acc: 0.89910s - loss: 0.2907  - ETA: 0s - loss: 0.2859 - acc: 0.89 - ETA: 0s - loss: 0.2849 - acc: 0.8\n",
      "Epoch 6/100\n",
      "32950/32950 [==============================] - 1s 43us/sample - loss: 0.2842 - acc: 0.89920s - loss: 0.2815 - \n",
      "Epoch 7/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2837 - acc: 0.89940s - loss: 0.2860 -\n",
      "Epoch 8/100\n",
      "32950/32950 [==============================] - 1s 36us/sample - loss: 0.2831 - acc: 0.8994\n",
      "Epoch 9/100\n",
      "32950/32950 [==============================] - 1s 36us/sample - loss: 0.2828 - acc: 0.8991\n",
      "Epoch 10/100\n",
      "32950/32950 [==============================] - 1s 36us/sample - loss: 0.2822 - acc: 0.8995\n",
      "Epoch 11/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2819 - acc: 0.8996\n",
      "Epoch 12/100\n",
      "32950/32950 [==============================] - 1s 36us/sample - loss: 0.2815 - acc: 0.89930s - loss: 0.2829\n",
      "Epoch 13/100\n",
      "32950/32950 [==============================] - 1s 38us/sample - loss: 0.2812 - acc: 0.8994\n",
      "Epoch 14/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2808 - acc: 0.8993\n",
      "Epoch 15/100\n",
      "32950/32950 [==============================] - 1s 35us/sample - loss: 0.2804 - acc: 0.8995\n",
      "Epoch 16/100\n",
      "32950/32950 [==============================] - 1s 36us/sample - loss: 0.2801 - acc: 0.8995\n",
      "Epoch 17/100\n",
      "32950/32950 [==============================] - 1s 36us/sample - loss: 0.2798 - acc: 0.8997\n",
      "Epoch 18/100\n",
      "32950/32950 [==============================] - 1s 36us/sample - loss: 0.2795 - acc: 0.8996\n",
      "Epoch 19/100\n",
      "32950/32950 [==============================] - 1s 39us/sample - loss: 0.2794 - acc: 0.8997\n",
      "Epoch 20/100\n",
      "32950/32950 [==============================] - 1s 36us/sample - loss: 0.2792 - acc: 0.89950s - loss: 0.2783 - a\n",
      "Epoch 21/100\n",
      "32950/32950 [==============================] - 1s 36us/sample - loss: 0.2791 - acc: 0.89950s - loss: 0.28\n",
      "Epoch 22/100\n",
      "32950/32950 [==============================] - 1s 43us/sample - loss: 0.2790 - acc: 0.8995\n",
      "Epoch 23/100\n",
      "32950/32950 [==============================] - 1s 39us/sample - loss: 0.2790 - acc: 0.8995\n",
      "Epoch 24/100\n",
      "32950/32950 [==============================] - 1s 39us/sample - loss: 0.2790 - acc: 0.89940s - loss: 0.2741 -  - ETA: 0s - loss: 0.2789 - acc: 0.899\n",
      "Epoch 25/100\n",
      "32950/32950 [==============================] - 1s 38us/sample - loss: 0.2789 - acc: 0.8990\n",
      "Epoch 26/100\n",
      "32950/32950 [==============================] - 1s 45us/sample - loss: 0.2788 - acc: 0.89940s - loss: 0.2805 - acc: 0.8\n",
      "Epoch 27/100\n",
      "32950/32950 [==============================] - 1s 43us/sample - loss: 0.2787 - acc: 0.89920s - loss: 0.2904 -  - ETA: 0s - loss: 0.2767 - ac\n",
      "Epoch 28/100\n",
      "32950/32950 [==============================] - 1s 43us/sample - loss: 0.2788 - acc: 0.8991\n",
      "Epoch 29/100\n",
      "32950/32950 [==============================] - 2s 52us/sample - loss: 0.2789 - acc: 0.8993\n",
      "Epoch 30/100\n",
      "32950/32950 [==============================] - 1s 38us/sample - loss: 0.2787 - acc: 0.89920s - loss: 0.2777 - acc: 0.90 - ETA: 0s - loss: 0.2811 - acc\n",
      "Epoch 31/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2788 - acc: 0.8993\n",
      "Epoch 32/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2786 - acc: 0.8994\n",
      "Epoch 33/100\n",
      "32950/32950 [==============================] - 1s 36us/sample - loss: 0.2788 - acc: 0.8995\n",
      "Epoch 34/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2787 - acc: 0.8993\n",
      "Epoch 35/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2786 - acc: 0.8996\n",
      "Epoch 36/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2788 - acc: 0.89911s - loss: 0.2852  - ETA: 0s - loss: 0.2761 - acc\n",
      "Epoch 37/100\n",
      "32950/32950 [==============================] - 1s 45us/sample - loss: 0.2787 - acc: 0.8992\n",
      "Epoch 38/100\n",
      "32950/32950 [==============================] - 1s 36us/sample - loss: 0.2786 - acc: 0.8997\n",
      "Epoch 39/100\n",
      "32950/32950 [==============================] - 1s 36us/sample - loss: 0.2785 - acc: 0.8994\n",
      "Epoch 40/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2787 - acc: 0.8992\n",
      "Epoch 41/100\n",
      "32950/32950 [==============================] - 1s 36us/sample - loss: 0.2786 - acc: 0.8993\n",
      "Epoch 42/100\n",
      "32950/32950 [==============================] - 1s 36us/sample - loss: 0.2786 - acc: 0.8990\n",
      "Epoch 43/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2786 - acc: 0.8994\n",
      "Epoch 44/100\n",
      "32950/32950 [==============================] - 1s 41us/sample - loss: 0.2786 - acc: 0.8992\n",
      "Epoch 45/100\n",
      "32950/32950 [==============================] - 1s 36us/sample - loss: 0.2787 - acc: 0.89950s - loss: 0.27\n",
      "Epoch 46/100\n",
      "32950/32950 [==============================] - 1s 36us/sample - loss: 0.2785 - acc: 0.8996\n",
      "Epoch 47/100\n",
      "32950/32950 [==============================] - 1s 41us/sample - loss: 0.2786 - acc: 0.8994\n",
      "Epoch 48/100\n",
      "32950/32950 [==============================] - 2s 51us/sample - loss: 0.2783 - acc: 0.89960s - loss: 0.2773 - acc:\n",
      "Epoch 49/100\n",
      "32950/32950 [==============================] - 2s 48us/sample - loss: 0.2784 - acc: 0.89921s - loss: 0\n",
      "Epoch 50/100\n",
      "32950/32950 [==============================] - 1s 38us/sample - loss: 0.2784 - acc: 0.8997\n",
      "Epoch 51/100\n",
      "32950/32950 [==============================] - 2s 46us/sample - loss: 0.2785 - acc: 0.8997\n",
      "Epoch 52/100\n",
      "32950/32950 [==============================] - 1s 39us/sample - loss: 0.2785 - acc: 0.89950s - loss: 0.2768 - acc\n",
      "Epoch 53/100\n",
      "32950/32950 [==============================] - 2s 52us/sample - loss: 0.2784 - acc: 0.89960s - loss\n",
      "Epoch 54/100\n",
      "32950/32950 [==============================] - 2s 47us/sample - loss: 0.2783 - acc: 0.89920s - loss:\n",
      "Epoch 55/100\n",
      "32950/32950 [==============================] - 1s 45us/sample - loss: 0.2785 - acc: 0.8998\n",
      "Epoch 56/100\n",
      "32950/32950 [==============================] - 2s 55us/sample - loss: 0.2783 - acc: 0.8996\n",
      "Epoch 57/100\n",
      "32950/32950 [==============================] - 2s 49us/sample - loss: 0.2783 - acc: 0.89951s - loss: 0. - ETA: 0s - loss: 0.2758 - acc: 0.9 - ETA: 0s - loss: 0.2780 - acc: 0.89\n",
      "Epoch 58/100\n",
      "32950/32950 [==============================] - 1s 45us/sample - loss: 0.2783 - acc: 0.8992\n",
      "Epoch 59/100\n",
      "32950/32950 [==============================] - 1s 41us/sample - loss: 0.2783 - acc: 0.8998\n",
      "Epoch 60/100\n",
      "32950/32950 [==============================] - 1s 36us/sample - loss: 0.2783 - acc: 0.89970s - loss: 0.2777 - acc: 0.8\n",
      "Epoch 61/100\n",
      "32950/32950 [==============================] - 1s 36us/sample - loss: 0.2782 - acc: 0.8998\n",
      "Epoch 62/100\n",
      "32950/32950 [==============================] - 1s 36us/sample - loss: 0.2784 - acc: 0.89920s - loss: 0.2791 - a\n",
      "Epoch 63/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2784 - acc: 0.90030s - loss: 0.2711 \n",
      "Epoch 64/100\n",
      "32950/32950 [==============================] - 1s 36us/sample - loss: 0.2784 - acc: 0.8994\n",
      "Epoch 65/100\n",
      "32950/32950 [==============================] - 1s 35us/sample - loss: 0.2783 - acc: 0.8993\n",
      "Epoch 66/100\n",
      "32950/32950 [==============================] - 1s 36us/sample - loss: 0.2782 - acc: 0.9001\n",
      "Epoch 67/100\n",
      "32950/32950 [==============================] - 1s 38us/sample - loss: 0.2783 - acc: 0.8998\n",
      "Epoch 68/100\n",
      "32950/32950 [==============================] - 1s 39us/sample - loss: 0.2781 - acc: 0.8997\n",
      "Epoch 69/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2783 - acc: 0.8995\n",
      "Epoch 70/100\n",
      "32950/32950 [==============================] - 2s 47us/sample - loss: 0.2782 - acc: 0.8995\n",
      "Epoch 71/100\n",
      "32950/32950 [==============================] - 1s 42us/sample - loss: 0.2784 - acc: 0.8994\n",
      "Epoch 72/100\n",
      "32950/32950 [==============================] - 1s 39us/sample - loss: 0.2783 - acc: 0.8994\n",
      "Epoch 73/100\n",
      "32950/32950 [==============================] - 1s 44us/sample - loss: 0.2783 - acc: 0.8997\n",
      "Epoch 74/100\n",
      "32950/32950 [==============================] - 1s 43us/sample - loss: 0.2783 - acc: 0.8994\n",
      "Epoch 75/100\n",
      "32950/32950 [==============================] - 2s 49us/sample - loss: 0.2783 - acc: 0.89931s - l\n",
      "Epoch 76/100\n",
      "32950/32950 [==============================] - 1s 43us/sample - loss: 0.2782 - acc: 0.8995\n",
      "Epoch 77/100\n",
      "32950/32950 [==============================] - 1s 44us/sample - loss: 0.2784 - acc: 0.8994\n",
      "Epoch 78/100\n",
      "32950/32950 [==============================] - 1s 46us/sample - loss: 0.2781 - acc: 0.90000s - lo\n",
      "Epoch 79/100\n",
      "32950/32950 [==============================] - 2s 49us/sample - loss: 0.2781 - acc: 0.8994\n",
      "Epoch 80/100\n",
      "32950/32950 [==============================] - 1s 36us/sample - loss: 0.2782 - acc: 0.8995\n",
      "Epoch 81/100\n",
      "32950/32950 [==============================] - 1s 36us/sample - loss: 0.2783 - acc: 0.8995\n",
      "Epoch 82/100\n",
      "32950/32950 [==============================] - 1s 36us/sample - loss: 0.2781 - acc: 0.8995\n",
      "Epoch 83/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2781 - acc: 0.8998\n",
      "Epoch 84/100\n",
      "32950/32950 [==============================] - 1s 36us/sample - loss: 0.2781 - acc: 0.9001\n",
      "Epoch 85/100\n",
      "32950/32950 [==============================] - 1s 39us/sample - loss: 0.2782 - acc: 0.89930s - loss:  - ETA: 0s - loss: 0.2789 - acc: 0.899\n",
      "Epoch 86/100\n",
      "32950/32950 [==============================] - ETA: 0s - loss: 0.2775 - acc: 0.899 - 2s 60us/sample - loss: 0.2783 - acc: 0.8994\n",
      "Epoch 87/100\n",
      "32950/32950 [==============================] - 1s 36us/sample - loss: 0.2782 - acc: 0.90000s - loss: 0.2766 - acc: 0.9\n",
      "Epoch 88/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2782 - acc: 0.8996\n",
      "Epoch 89/100\n",
      "32950/32950 [==============================] - 1s 36us/sample - loss: 0.2780 - acc: 0.89990s - loss: 0\n",
      "Epoch 90/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2782 - acc: 0.8996\n",
      "Epoch 91/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2782 - acc: 0.8994\n",
      "Epoch 92/100\n",
      "32950/32950 [==============================] - 1s 35us/sample - loss: 0.2782 - acc: 0.89890s - loss: 0.2780 - acc: 0\n",
      "Epoch 93/100\n",
      "32950/32950 [==============================] - 1s 43us/sample - loss: 0.2782 - acc: 0.8990\n",
      "Epoch 94/100\n",
      "32950/32950 [==============================] - 1s 36us/sample - loss: 0.2782 - acc: 0.8998\n",
      "Epoch 95/100\n",
      "32950/32950 [==============================] - 1s 36us/sample - loss: 0.2781 - acc: 0.8999\n",
      "Epoch 96/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2781 - acc: 0.8998\n",
      "Epoch 97/100\n",
      "32950/32950 [==============================] - 1s 36us/sample - loss: 0.2782 - acc: 0.89980s - loss: 0.2751 - ac\n",
      "Epoch 98/100\n",
      "32950/32950 [==============================] - 1s 36us/sample - loss: 0.2781 - acc: 0.8992\n",
      "Epoch 99/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2781 - acc: 0.8996\n",
      "Epoch 100/100\n",
      "32950/32950 [==============================] - 2s 46us/sample - loss: 0.2783 - acc: 0.9000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a4c174990>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Input layer and 1st hidden layer\n",
    "classifierANN_4.add(Dense(6, activation = 'relu'))\n",
    "#Output layer\n",
    "classifierANN_4.add(Dense(1, activation = 'sigmoid'))\n",
    "#Compilion the ANN\n",
    "classifierANN_4.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "#Fitting classifier to the training set \n",
    "classifierANN_4.fit(X_train_reduced, y_train, batch_size=32, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting y value\n",
    "y_pred = classifierANN_4.predict(X_test_reduced)\n",
    "y_pred = (y_pred>0.5)\n",
    "\n",
    "#Checking accuracy score\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "acc_4 = accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifier 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "32950/32950 [==============================] - 1s 44us/sample - loss: 0.3611 - acc: 0.8793\n",
      "Epoch 2/100\n",
      "32950/32950 [==============================] - 1s 38us/sample - loss: 0.2902 - acc: 0.8975\n",
      "Epoch 3/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2871 - acc: 0.8992\n",
      "Epoch 4/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2858 - acc: 0.89950s - loss: 0.\n",
      "Epoch 5/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2851 - acc: 0.8995\n",
      "Epoch 6/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2849 - acc: 0.8996\n",
      "Epoch 7/100\n",
      "32950/32950 [==============================] - 1s 44us/sample - loss: 0.2848 - acc: 0.89970s - loss: 0.2867 - ac\n",
      "Epoch 8/100\n",
      "32950/32950 [==============================] - 1s 38us/sample - loss: 0.2846 - acc: 0.8998\n",
      "Epoch 9/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2844 - acc: 0.8996\n",
      "Epoch 10/100\n",
      "32950/32950 [==============================] - 1s 38us/sample - loss: 0.2843 - acc: 0.8996\n",
      "Epoch 11/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2841 - acc: 0.8994\n",
      "Epoch 12/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2840 - acc: 0.8998\n",
      "Epoch 13/100\n",
      "32950/32950 [==============================] - 1s 36us/sample - loss: 0.2840 - acc: 0.8999\n",
      "Epoch 14/100\n",
      "32950/32950 [==============================] - 1s 38us/sample - loss: 0.2839 - acc: 0.89990s - loss: 0.2816 - ac\n",
      "Epoch 15/100\n",
      "32950/32950 [==============================] - 1s 38us/sample - loss: 0.2838 - acc: 0.8997\n",
      "Epoch 16/100\n",
      "32950/32950 [==============================] - 1s 43us/sample - loss: 0.2837 - acc: 0.8998\n",
      "Epoch 17/100\n",
      "32950/32950 [==============================] - 1s 38us/sample - loss: 0.2837 - acc: 0.89950s - loss: 0\n",
      "Epoch 18/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2836 - acc: 0.89970s - loss: 0.284\n",
      "Epoch 19/100\n",
      "32950/32950 [==============================] - 1s 38us/sample - loss: 0.2835 - acc: 0.89980s - loss: 0\n",
      "Epoch 20/100\n",
      "32950/32950 [==============================] - 1s 38us/sample - loss: 0.2835 - acc: 0.8995\n",
      "Epoch 21/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2835 - acc: 0.8997\n",
      "Epoch 22/100\n",
      "32950/32950 [==============================] - 1s 38us/sample - loss: 0.2834 - acc: 0.8998\n",
      "Epoch 23/100\n",
      "32950/32950 [==============================] - 1s 38us/sample - loss: 0.2834 - acc: 0.8999\n",
      "Epoch 24/100\n",
      "32950/32950 [==============================] - 2s 46us/sample - loss: 0.2833 - acc: 0.89950s - loss: 0.2845 - acc: 0.89\n",
      "Epoch 25/100\n",
      "32950/32950 [==============================] - 1s 38us/sample - loss: 0.2834 - acc: 0.89990s - loss: 0.2872 - acc: 0.\n",
      "Epoch 26/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2833 - acc: 0.9000\n",
      "Epoch 27/100\n",
      "32950/32950 [==============================] - 1s 39us/sample - loss: 0.2833 - acc: 0.90010s - loss: 0.2\n",
      "Epoch 28/100\n",
      "32950/32950 [==============================] - 1s 40us/sample - loss: 0.2833 - acc: 0.90000s - loss: 0.28\n",
      "Epoch 29/100\n",
      "32950/32950 [==============================] - 1s 38us/sample - loss: 0.2832 - acc: 0.8997\n",
      "Epoch 30/100\n",
      "32950/32950 [==============================] - 1s 39us/sample - loss: 0.2833 - acc: 0.8997\n",
      "Epoch 31/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2832 - acc: 0.8999\n",
      "Epoch 32/100\n",
      "32950/32950 [==============================] - 1s 40us/sample - loss: 0.2832 - acc: 0.9000\n",
      "Epoch 33/100\n",
      "32950/32950 [==============================] - 1s 40us/sample - loss: 0.2831 - acc: 0.89970s - loss: 0.2838 - acc - ETA: 0s - loss: 0.2838 - acc: 0.8\n",
      "Epoch 34/100\n",
      "32950/32950 [==============================] - 1s 38us/sample - loss: 0.2832 - acc: 0.8997\n",
      "Epoch 35/100\n",
      "32950/32950 [==============================] - 1s 43us/sample - loss: 0.2830 - acc: 0.8998\n",
      "Epoch 36/100\n",
      "32950/32950 [==============================] - 1s 44us/sample - loss: 0.2831 - acc: 0.8996\n",
      "Epoch 37/100\n",
      "32950/32950 [==============================] - 1s 39us/sample - loss: 0.2831 - acc: 0.8997\n",
      "Epoch 38/100\n",
      "32950/32950 [==============================] - 1s 39us/sample - loss: 0.2831 - acc: 0.8999\n",
      "Epoch 39/100\n",
      "32950/32950 [==============================] - 1s 39us/sample - loss: 0.2829 - acc: 0.9002\n",
      "Epoch 40/100\n",
      "32950/32950 [==============================] - 1s 41us/sample - loss: 0.2830 - acc: 0.8998\n",
      "Epoch 41/100\n",
      "32950/32950 [==============================] - 1s 45us/sample - loss: 0.2831 - acc: 0.90000s - loss: 0.2803 - ac - ETA: 0s - loss: 0.2830 - acc: 0.900\n",
      "Epoch 42/100\n",
      "32950/32950 [==============================] - 2s 47us/sample - loss: 0.2830 - acc: 0.9001\n",
      "Epoch 43/100\n",
      "32950/32950 [==============================] - 2s 58us/sample - loss: 0.2829 - acc: 0.8996\n",
      "Epoch 44/100\n",
      "32950/32950 [==============================] - 1s 45us/sample - loss: 0.2829 - acc: 0.89960s - loss: 0.2844 - ac\n",
      "Epoch 45/100\n",
      "32950/32950 [==============================] - 2s 46us/sample - loss: 0.2830 - acc: 0.8998\n",
      "Epoch 46/100\n",
      "32950/32950 [==============================] - 2s 53us/sample - loss: 0.2827 - acc: 0.8998\n",
      "Epoch 47/100\n",
      "32950/32950 [==============================] - 2s 50us/sample - loss: 0.2830 - acc: 0.9002\n",
      "Epoch 48/100\n",
      "32950/32950 [==============================] - 1s 44us/sample - loss: 0.2829 - acc: 0.8995\n",
      "Epoch 49/100\n",
      "32950/32950 [==============================] - 1s 39us/sample - loss: 0.2827 - acc: 0.8995\n",
      "Epoch 50/100\n",
      "32950/32950 [==============================] - 1s 42us/sample - loss: 0.2829 - acc: 0.8996\n",
      "Epoch 51/100\n",
      "32950/32950 [==============================] - 2s 53us/sample - loss: 0.2829 - acc: 0.89950s - loss: 0.2827 - acc: 0.89 - ETA: 0s - loss: 0.2827 - acc: \n",
      "Epoch 52/100\n",
      "32950/32950 [==============================] - 1s 43us/sample - loss: 0.2829 - acc: 0.8999\n",
      "Epoch 53/100\n",
      "32950/32950 [==============================] - 1s 39us/sample - loss: 0.2828 - acc: 0.89980s - loss: 0.2856 - ac\n",
      "Epoch 54/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2830 - acc: 0.89960s - loss: 0.27\n",
      "Epoch 55/100\n",
      "32950/32950 [==============================] - 1s 40us/sample - loss: 0.2828 - acc: 0.8999\n",
      "Epoch 56/100\n",
      "32950/32950 [==============================] - 2s 47us/sample - loss: 0.2828 - acc: 0.9000\n",
      "Epoch 57/100\n",
      "32950/32950 [==============================] - 1s 41us/sample - loss: 0.2828 - acc: 0.8996\n",
      "Epoch 58/100\n",
      "32950/32950 [==============================] - 1s 38us/sample - loss: 0.2827 - acc: 0.89980s - loss: 0.2816 - acc: 0.\n",
      "Epoch 59/100\n",
      "32950/32950 [==============================] - 2s 59us/sample - loss: 0.2828 - acc: 0.8995\n",
      "Epoch 60/100\n",
      "32950/32950 [==============================] - 1s 41us/sample - loss: 0.2828 - acc: 0.8997\n",
      "Epoch 61/100\n",
      "32950/32950 [==============================] - 1s 38us/sample - loss: 0.2827 - acc: 0.90000s - loss: 0.28\n",
      "Epoch 62/100\n",
      "32950/32950 [==============================] - 1s 39us/sample - loss: 0.2828 - acc: 0.8996\n",
      "Epoch 63/100\n",
      "32950/32950 [==============================] - 1s 39us/sample - loss: 0.2827 - acc: 0.8997\n",
      "Epoch 64/100\n",
      "32950/32950 [==============================] - 2s 46us/sample - loss: 0.2826 - acc: 0.8999\n",
      "Epoch 65/100\n",
      "32950/32950 [==============================] - 1s 38us/sample - loss: 0.2827 - acc: 0.8996\n",
      "Epoch 66/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2827 - acc: 0.89970s - loss: 0.2840 - acc: 0.\n",
      "Epoch 67/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2827 - acc: 0.8998\n",
      "Epoch 68/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2826 - acc: 0.8998\n",
      "Epoch 69/100\n",
      "32950/32950 [==============================] - 1s 35us/sample - loss: 0.2828 - acc: 0.89980s - loss: 0.2825 - acc: \n",
      "Epoch 70/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2827 - acc: 0.89960s - loss: 0\n",
      "Epoch 71/100\n",
      "32950/32950 [==============================] - 1s 41us/sample - loss: 0.2826 - acc: 0.8995\n",
      "Epoch 72/100\n",
      "32950/32950 [==============================] - 1s 45us/sample - loss: 0.2826 - acc: 0.8996\n",
      "Epoch 73/100\n",
      "32950/32950 [==============================] - 1s 45us/sample - loss: 0.2826 - acc: 0.89921s - loss: 0.2\n",
      "Epoch 74/100\n",
      "32950/32950 [==============================] - 1s 39us/sample - loss: 0.2825 - acc: 0.8997\n",
      "Epoch 75/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2827 - acc: 0.8998\n",
      "Epoch 76/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2825 - acc: 0.8995\n",
      "Epoch 77/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2825 - acc: 0.8994\n",
      "Epoch 78/100\n",
      "32950/32950 [==============================] - 1s 43us/sample - loss: 0.2827 - acc: 0.8997\n",
      "Epoch 79/100\n",
      "32950/32950 [==============================] - 1s 38us/sample - loss: 0.2826 - acc: 0.89970s - loss: 0.\n",
      "Epoch 80/100\n",
      "32950/32950 [==============================] - 1s 39us/sample - loss: 0.2824 - acc: 0.89960s - loss: 0.2819 - acc:\n",
      "Epoch 81/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2825 - acc: 0.8998\n",
      "Epoch 82/100\n",
      "32950/32950 [==============================] - 1s 36us/sample - loss: 0.2825 - acc: 0.8990\n",
      "Epoch 83/100\n",
      "32950/32950 [==============================] - 1s 38us/sample - loss: 0.2826 - acc: 0.8997\n",
      "Epoch 84/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2827 - acc: 0.8995\n",
      "Epoch 85/100\n",
      "32950/32950 [==============================] - 1s 40us/sample - loss: 0.2825 - acc: 0.9002\n",
      "Epoch 86/100\n",
      "32950/32950 [==============================] - 1s 36us/sample - loss: 0.2824 - acc: 0.8995\n",
      "Epoch 87/100\n",
      "32950/32950 [==============================] - 1s 35us/sample - loss: 0.2826 - acc: 0.8993\n",
      "Epoch 88/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2824 - acc: 0.8998\n",
      "Epoch 89/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2825 - acc: 0.89980s - loss: 0.2822 - acc: 0.89\n",
      "Epoch 90/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2825 - acc: 0.8998\n",
      "Epoch 91/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2825 - acc: 0.9000\n",
      "Epoch 92/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2826 - acc: 0.89960s - loss: 0.2865 -\n",
      "Epoch 93/100\n",
      "32950/32950 [==============================] - 1s 38us/sample - loss: 0.2824 - acc: 0.89980s - loss: 0.2783  - ETA: 0s - loss: 0.2807 - acc: 0\n",
      "Epoch 94/100\n",
      "32950/32950 [==============================] - 1s 43us/sample - loss: 0.2824 - acc: 0.8998\n",
      "Epoch 95/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2825 - acc: 0.89970s - loss: 0.\n",
      "Epoch 96/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2825 - acc: 0.8996\n",
      "Epoch 97/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2824 - acc: 0.8997\n",
      "Epoch 98/100\n",
      "32950/32950 [==============================] - 1s 35us/sample - loss: 0.2825 - acc: 0.8995\n",
      "Epoch 99/100\n",
      "32950/32950 [==============================] - 1s 37us/sample - loss: 0.2826 - acc: 0.8995\n",
      "Epoch 100/100\n",
      "32950/32950 [==============================] - 1s 38us/sample - loss: 0.2824 - acc: 0.89940s - loss: 0.2849 - a\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a38c12f10>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Input layer and 1st hidden layer\n",
    "classifierANN_5.add(Dense(4, activation = 'relu'))\n",
    "#Output layer\n",
    "classifierANN_5.add(Dense(1, activation = 'sigmoid'))\n",
    "#Compilion the ANN\n",
    "classifierANN_5.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "#Fitting classifier to the training set \n",
    "classifierANN_5.fit(X_train_reduced, y_train, batch_size=32, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting y value\n",
    "y_pred = classifierANN_5.predict(X_test_reduced)\n",
    "y_pred = (y_pred>0.5)\n",
    "\n",
    "#Checking accuracy score\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "acc_5 = accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier1</th>\n",
       "      <th>Classifier2</th>\n",
       "      <th>Classifier3</th>\n",
       "      <th>Classifier4</th>\n",
       "      <th>Classifier5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.896091</td>\n",
       "      <td>0.897062</td>\n",
       "      <td>0.896698</td>\n",
       "      <td>0.895727</td>\n",
       "      <td>0.896698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Classifier1  Classifier2  Classifier3  Classifier4  Classifier5\n",
       "0     0.896091     0.897062     0.896698     0.895727     0.896698"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = pd.DataFrame([acc_1, acc_2, acc_3, acc_4, acc_5]).transpose()\n",
    "scores.columns = ['Classifier1', 'Classifier2', 'Classifier3', 'Classifier4', 'Classifier5']\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second classifier has the best accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
